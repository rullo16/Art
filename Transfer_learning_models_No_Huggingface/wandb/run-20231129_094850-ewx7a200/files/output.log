No such comm: c12a2efc16e34848acf7fa1a8413eb6a
No such comm: 5580d42c2a394b4dad1208f738e06882
No such comm: 871d2a5bbf2f4cb083f7db2bdba19b0e
No such comm: 0764ae53375d4990a6083e889f5d8bc5
No such comm: 3fa6e393fd8942c2aa17f3c43164467d
No such comm: 6a6223bb9be04418824e525522864b71
No such comm: 93b8554012974b679b5149e418b1e885
No such comm: db3db1fd8ffc439ea77af855e911a9e0
No such comm: 6a2bf254c93b4cd6b2279f7fe47e4463
No such comm: 2bf2c045765b4965b46285019bce6265
No such comm: d1973ac3e4df49098a4fe62e0c30ca3b
No such comm: 95a00ecd598a42efad98d1c799f5491e
No such comm: 1f94dc1ecdab448ea508f1ca0235f625
No such comm: 8b3821778b7b4413a61c5914fdab15ab
No such comm: efc6b75842ce4f23819628cb2744c08c
No such comm: b2f5cb2e476644afbdc2f2f7d591b3fd
  1%|          | 30/3000 [00:00<00:30, 98.56it/s]

















100%|██████████| 3000/3000 [00:35<00:00, 83.85it/s]
 49%|████▉     | 1463/3000 [00:00<00:00, 2560.80it/s]
mean and std before normalize:
Mean of the image: tensor([0.4685, 0.3801, 0.3472])

100%|██████████| 3000/3000 [00:01<00:00, 2430.54it/s]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Feature batch shape: torch.Size([50, 3, 256, 256])
Labels batch shape: 50
Label_tokenized: tensor([[    1,     3,    63,  ...,     0,     0,     0],
        [    1,     3,  2688,  ...,  1621,  7998,    19],
        [    1,   282,    53,  ...,  7299, 15092,  4762],
        ...,
        [    1,     3,   294,  ...,     7,  7962,    11],
        [    1,   282,    21,  ...,  2152,    11, 12863],
        [    1,   282,   174,  ...,  2147,    84,    69]])
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Feature batch shape: torch.Size([50, 3, 256, 256])
Labels batch shape: 50
Label_tokenized: tensor([[    1,     3,   303,  ...,   818,  1262,   942],
        [    1,  9718, 16023,  ...,    71, 16054,     5],
        [    1,   691,  4058,  ...,   276,  3837,     7],
        ...,
        [    1,     3,    63,  ...,     0,     0,     0],
        [    1,   276,     4,  ...,     7, 10236,    90],
        [    1,   749,  9407,  ...,    68,     7,  9416]])
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Feature batch shape: torch.Size([50, 3, 256, 256])
Labels batch shape: 50
Label_tokenized: tensor([[    1,     3,  1301,  ...,    13,     7,   259],
        [    1,     3,  2032,  ...,     0,     0,     0],
        [    1,   282,  1572,  ...,  3134,  2055, 14217],
        ...,
        [    1,   282,     7,  ...,     0,     0,     0],
        [    1, 14754,    69,  ...,  8012,    24,     7],
        [    1,  7168,   125,  ...,   900,     5,     7]])
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Feature batch shape: torch.Size([50, 3, 256, 256])
Labels batch shape: 50
Label_tokenized: tensor([[   1,  276,    4,  ...,    0,    0,    0],
        [   1,  276, 3726,  ...,  297, 4324,   11],
        [   1,  276,  503,  ...,   87,  837,   19],
        ...,
        [   1,    3,  900,  ...,    0,    0,    0],
        [   1,  276,   13,  ...,    7, 9724, 9725],
        [   1,    3,   63,  ...,  191,   87, 1064]])