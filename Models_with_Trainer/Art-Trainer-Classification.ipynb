{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install datasets\n",
    "%pip install transformers\n",
    "%pip install sentencepiece\n",
    "%pip install diffusers --upgrade\n",
    "%pip install invisible_watermark accelerate safetensors\n",
    "%pip install accelerate\n",
    "%pip install jiwer\n",
    "%pip install evaluate --upgrade\n",
    "%pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from PIL import Image, ImageFile\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoProcessor\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "1. **Loading Data:**\n",
    "    - The code first checks if a variable named data is not already defined in the local namespace. If it's not defined, it loads a CSV file named 'described_dataset_label.csv' located one directory above the current directory.\n",
    "    - The data is read using Pandas read_csv() function, specifying the file path, delimiter (sep parameter) as '\\t' (tab-separated), and encoding as 'latin-1'.\n",
    "    - It then selects the first 20,000 rows of the dataset using .iloc[:20000].\n",
    "    - The column names are then renamed for consistency using .rename() method.\n",
    "    - Finally, it selects only specific columns ('image', 'author', 'title', 'style') using indexing.\n",
    "\n",
    "2. **Data Preprocessing:**\n",
    "    - It prefixes the 'image' column values with a dot ('.') using list comprehension and assigns the result back to the 'image' column.\n",
    "\n",
    "3. **Label Encoding:**\n",
    "    - Load the 'labels_auth' and 'labels_sty' variables from the json files with the encoding.\n",
    "    - It then creates dictionaries `label2id_auth` and `id2label_auth` to map authors to unique IDs and vice versa.\n",
    "    - Similarly, it creates dictionaries `label2id_sty` and `id2label_sty` to map styles to unique IDs and vice versa.\n",
    "\n",
    "## Reasoning:\n",
    "- **Loading Data:** \n",
    "    - The code loads a dataset from a CSV file, presumably containing information about images such as their authors, titles, and styles.\n",
    "    - It selects only a subset of the dataset (first 20,000 rows) for faster processing or due to memory constraints.\n",
    "    - Renaming and selecting specific columns ensure consistency and relevance to the task.\n",
    "\n",
    "- **Data Preprocessing:**\n",
    "    - The prefixing of the 'image' column values with a dot seems to be a formatting step, possibly to ensure compatibility with file paths.\n",
    "\n",
    "- **Label Encoding:**\n",
    "    - Encoding labels into numerical IDs is a common preprocessing step in machine learning tasks. It converts categorical data into a format that machine learning algorithms can understand.\n",
    "    - These mappings (`label2id_auth`, `id2label_auth`, `label2id_sty`, `id2label_sty`) facilitate the conversion between labels and their corresponding numerical IDs during training and prediction stages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../described_dataset_label.csv',sep='\\t',encoding='utf-8')\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data = data[:20000]\n",
    "data = data.rename(columns={'FILE':'image','AUTHOR':'author', 'TITLE': 'title', 'TECHNIQUE':'style'})\n",
    "data = data[['image','author','title','style']]\n",
    "data['image'] = [f'.{x}' for x in data['image']]\n",
    "data['author'] = [x.lower() for x in data['author']]\n",
    "data['style'] = [x.split(',')[0].lower() for x in data['style']]\n",
    "\n",
    "with open('../label_author.json', 'r') as f:\n",
    "    labels_author = json.load(f)\n",
    "label2id_auth, id2label_auth = dict(), dict()\n",
    "for i, label in labels_author.items():\n",
    "    i= int(i)\n",
    "    id2label_auth[i]=label\n",
    "    label2id_auth[label]=i\n",
    "\n",
    "with open('../label_style.json', 'r') as f:\n",
    "    labels_sty = json.load(f)\n",
    "label2id_sty, id2label_sty = dict(), dict()\n",
    "for i, label in labels_sty.items():\n",
    "    i=int(i)\n",
    "    label2id_sty[label]=i\n",
    "    id2label_sty[i]=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label2id_auth)\n",
    "print(labels_author)\n",
    "print(len(labels_author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Label Mapping:**\n",
    "    - It utilizes the `map()` function in Pandas to replace each unique label in the 'author' and 'style' columns with their corresponding numerical IDs stored in the `label2id_auth` and `label2id_sty` dictionaries, respectively.\n",
    "    - This transformation effectively converts categorical labels into numerical representations, facilitating machine learning model training.\n",
    "\n",
    "Mapping categorical labels to numerical IDs is essential for many machine learning algorithms, as they typically require numerical input. By replacing categorical labels with numerical IDs, the data becomes suitable for training predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['author'] = data['author'].map(label2id_auth)\n",
    "data['style'] = data['style'].map(label2id_sty)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we create a Dataset from the processed data while also casting the image data to a PIL Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(data).cast_column('image',datasets.Image())\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[500]\n",
    "\n",
    "image = sample['image']\n",
    "height,width = image.size\n",
    "display(image.resize((int(0.3*height),int(0.3*width))))\n",
    "author = id2label_auth[sample['author']]\n",
    "technique = id2label_sty[sample['style']]\n",
    "print(f'Author: {author}')\n",
    "print(f'Technique: {technique}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Checkpoint Initialization (`checkpoint_clas`):**\n",
    "    - The variable `checkpoint_clas` is assigned the string 'google/vit-base-patch16-224-in21k'.\n",
    "    - This string likely serves as a reference to the specific pre-trained model checkpoint. \n",
    "    - The mentioned model, 'vit-base-patch16-224', is a Vision Transformer model with a patch size of 16x16 and input image size of 224x224. The 'in21k' part indicates that the model has been pre-trained on an ImageNet-21k dataset, which includes 21,000 classes.\n",
    "\n",
    "2. **Processor Initialization (`processor_clas`):**\n",
    "    - The `AutoProcessor.from_pretrained()` method is used to initialize a processor for the specified pre-trained model.\n",
    "    - The `AutoProcessor` class automatically selects the appropriate processor based on the provided checkpoint string.\n",
    "    - The initialized processor is capable of handling various preprocessing tasks required for input data, such as tokenization, resizing, and normalization, to make it compatible with the model's architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "For our classification task, we utilize a Vision Transformer (ViT) model. The ViT model, designed by Google, has demonstrated excellent performance in image classification tasks. It divides each image into patches and applies a transformer encoder to learn patterns and features from these patches.\n",
    "Loading the Model\n",
    "\n",
    "We load a pre-trained ViT model and its associated processor for our classification task. Using a pre-trained model allows us to leverage learned features from large datasets, improving the performance of our model on our specific task with less training data and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_clas = 'google/vit-base-patch16-224-in21k'\n",
    "processor_clas = AutoProcessor.from_pretrained(checkpoint_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Normalization:**\n",
    "    - The code initializes a normalization transform (`normalize`) using the `Normalize` class from `torchvision.transforms`. \n",
    "    - The mean and standard deviation for normalization are obtained from the `processor_clas` object, which likely contains parameters specific to the pre-trained model's preprocessing requirements.\n",
    "    - `processor_clas.image_mean` and `processor_clas.image_std` are used to set the mean and standard deviation, respectively, for normalizing the input images.\n",
    "\n",
    "2. **Image Size Determination:**\n",
    "    - The variable `size` is calculated based on the dimensions specified in the `processor_clas` object.\n",
    "    - If the `processor_clas.size` dictionary contains a key named \"shortest_edge\", the `size` is set to the value corresponding to this key. Otherwise, the `size` is set to a tuple containing the height and width specified in the `processor_clas.size` dictionary.\n",
    "\n",
    "3. **Compose Transformations:**\n",
    "    - A sequence of transformations is defined using the `Compose` class from `torchvision.transforms`. \n",
    "    - The defined transformations include:\n",
    "        - `RandomResizedCrop`: This transformation performs a random crop of the input image and resizes it to the specified size. The `size` parameter is set to the determined `size`.\n",
    "        - `ToTensor`: This transformation converts the image data into a PyTorch tensor.\n",
    "        - `normalize`: This transformation normalizes the tensor values using the specified mean and standard deviation.\n",
    "\n",
    "## Reasoning:\n",
    "- **Normalization:**\n",
    "    - Normalizing the input images ensures that the pixel values are scaled to a range suitable for the model's training, typically between 0 and 1 or -1 and 1.\n",
    "    - Normalization based on the mean and standard deviation of the dataset helps in stabilizing and speeding up the training process.\n",
    "\n",
    "- **Compose Transformations:**\n",
    "    - Composing the transformations into a pipeline allows for efficient preprocessing of input images before feeding them into the neural network.\n",
    "    - Random cropping followed by resizing and conversion to tensor are common preprocessing steps used in image classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "normalize = Normalize(mean=processor_clas.image_mean, std=processor_clas.image_std)\n",
    "\n",
    "size = (\n",
    "    processor_clas.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in processor_clas.size\n",
    "    else (processor_clas.size[\"height\"], processor_clas.size[\"width\"])\n",
    ")\n",
    "\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data Preparation\n",
    "For both Author and Style we create two different datasets, by removing the unwanted columns and then we split this dataset into train and test sets. We chose a test size of 0.3 as it worked better for us to have a sliglty bigger test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author\n",
    "auth_data = dataset.remove_columns(['style','title']).rename_column('author','label')\n",
    "auth_dataset = auth_data.train_test_split(test_size=0.3)\n",
    "auth_dataset = auth_dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Style\n",
    "sty_data = dataset.remove_columns(['author','title']).rename_column('style','label')\n",
    "sty_dataset = sty_data.train_test_split(test_size=0.3)\n",
    "sty_dataset = sty_dataset.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to train the models through the Trainer class of the transformer library we need metrics which are used to evaluate the model as it is training. We use the accuracy, precision, recall and f1 score as metrics for both models.\n",
    "\n",
    "1. **Function Definition (`compute_metrics`):**\n",
    "    - This function takes a `pred` parameter, presumably containing predictions made by a classification model.\n",
    "    - It extracts true labels (`labels`) and predicted labels (`preds`) from the `pred` object.\n",
    "    \n",
    "2. **Metrics Calculation:**\n",
    "    - **Accuracy:** \n",
    "        - The accuracy is calculated using the `accuracy_score` function from scikit-learn, comparing true labels (`labels`) and predicted labels (`preds`).\n",
    "    - **Precision, Recall, and F1-score:** \n",
    "        - Precision, recall, and F1-score are calculated using `precision_score`, `recall_score`, and `f1_score` functions, respectively, from scikit-learn.\n",
    "        - These metrics are computed with the 'weighted' averaging strategy to handle class imbalance. The `zero_division` parameter is set to 0 to handle cases where there are no true positives for a particular class, ensuring no division by zero errors.\n",
    "        \n",
    "3. **Return Statement:**\n",
    "    - The function returns a dictionary containing the computed evaluation metrics (`accuracy`, `precision`, `recall`, `f1`).\n",
    "\n",
    "## Reasoning:\n",
    "- **Metric Selection:**\n",
    "    - Accuracy, precision, recall, and F1-score are commonly used metrics for evaluating classification models.\n",
    "    - Accuracy provides an overall assessment of the model's correctness.\n",
    "    - Precision measures the model's ability to correctly identify positive instances out of all instances predicted as positive.\n",
    "    - Recall measures the model's ability to correctly identify positive instances out of all actual positive instances.\n",
    "    - F1-score is the harmonic mean of precision and recall, providing a balance between the two metrics.\n",
    "\n",
    "- **Weighted Averaging:**\n",
    "    - Using weighted averaging for precision, recall, and F1-score is suitable for handling class imbalance scenarios where some classes may have significantly more samples than others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# def compute_metrics(pred):\n",
    "#     labels = pred.label_ids\n",
    "#     preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "#     # Calculate accuracy\n",
    "#     accuracy = accuracy_score(labels, preds)\n",
    "#     return accuracy\n",
    "\n",
    "#    # Calculate precision, recall, and F1-score\n",
    "#     precision = precision_score(labels, preds, average='weighted',zero_division=0)\n",
    "#     recall = recall_score(labels, preds, average='weighted',zero_division=0)\n",
    "#     f1 = f1_score(labels, preds, average='weighted',zero_division=0)\n",
    "    \n",
    "#     return {\n",
    "#         'accuracy': accuracy,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall,\n",
    "#         'f1': f1\n",
    "#     }\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code initializes and trains a classification model using the Hugging Face `Trainer` interface. It also defines training arguments (`auth_training_args`) and sets up the training process.\n",
    "This setup is used for both Author and Style labels.\n",
    "\n",
    "## Code Explanation:\n",
    "1. **Training Arguments Initialization (`auth_training_args`):**\n",
    "    - The code initializes a `TrainingArguments` object named `auth_training_args` with various parameters required for training the classification model.\n",
    "    - Key parameters include:\n",
    "        - `output_dir`: Specifies the directory where model checkpoints and other outputs will be saved.\n",
    "        - `evaluation_strategy`: Sets the evaluation strategy to perform evaluation at the end of each epoch.\n",
    "        - `learning_rate`: Sets the initial learning rate for the optimizer.\n",
    "        - `per_device_train_batch_size`: Specifies the batch size per GPU for training data.\n",
    "        - `gradient_accumulation_steps`: Accumulates gradients over multiple steps to effectively increase the batch size.\n",
    "        - `num_train_epochs`: Specifies the total number of training epochs.\n",
    "        - `metric_for_best_model`: Specifies the metric to monitor for determining the best model during training.\n",
    "        - `push_to_hub`: Specifies whether to push the trained model to the Hugging Face model hub after training.\n",
    "\n",
    "2. **Trainer Initialization (`auth_trainer`):**\n",
    "    - The code initializes a `Trainer` object named `auth_trainer` for training the classification model.\n",
    "    - Key arguments passed to the `Trainer` object include:\n",
    "        - `model`: Specifies the classification model (`vit_model_auth`) to be trained.\n",
    "        - `args`: Specifies the training arguments (`auth_training_args`) defined earlier.\n",
    "        - `data_collator`: Specifies the data collator object for batch processing.\n",
    "        - `train_dataset`: Specifies the training dataset (`auth_dataset['train']`).\n",
    "        - `eval_dataset`: Specifies the evaluation dataset (`auth_dataset['test']`).\n",
    "        - `tokenizer`: Specifies the tokenizer object (`processor_clas`) for tokenizing input data.\n",
    "        - `compute_metrics`: Specifies the function for computing evaluation metrics during training.\n",
    "\n",
    "3. **Training Process (`auth_trainer.train()`):**\n",
    "    - Initiates the training process using the `train()` method of the `Trainer` object (`auth_trainer`).\n",
    "    - The model is trained for the specified number of epochs (`num_train_epochs`).\n",
    "    - Training progress, evaluation metrics, and checkpoints are saved based on the parameters specified in the training arguments.\n",
    "\n",
    "4. **Memory Management (`torch.cuda.empty_cache()`):**\n",
    "    - Clears the unused memory caches on the GPU after training to free up memory resources.\n",
    "\n",
    "## Reasoning:\n",
    "- **Training Configuration:**\n",
    "    - The training arguments (`auth_training_args`) define various parameters crucial for training, such as batch size, learning rate, and evaluation strategy.\n",
    "    - These parameters are set based on empirical observations, best practices, and the specific requirements of the training task.\n",
    "\n",
    "- **Trainer Setup:**\n",
    "    - The `Trainer` object (`auth_trainer`) encapsulates the training process, including data loading, model training, evaluation, and checkpointing.\n",
    "    - By utilizing the Hugging Face `Trainer` interface, the code simplifies the training pipeline and provides convenient access to various training functionalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init_auth(trial):\n",
    "    return AutoModelForImageClassification.from_pretrained(\n",
    "        checkpoint_clas,\n",
    "        num_labels = len(labels_author),\n",
    "        id2label = id2label_auth,\n",
    "        label2id = label2id_auth\n",
    "    ).to(device)\n",
    "\n",
    "def model_init_sty(trial):\n",
    "    return AutoModelForImageClassification.from_pretrained(\n",
    "        checkpoint_clas,\n",
    "        num_labels = len(labels_sty),\n",
    "        id2label = id2label_sty,\n",
    "        label2id = label2id_sty\n",
    "    ).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Configuration\n",
    "\n",
    "We define training arguments to configure various parameters for the training process, including batch size, learning rate, and evaluation strategy. These parameters are crucial for optimizing the training process and ensuring effective model learning.\n",
    "Training Arguments\n",
    "\n",
    "## The training arguments specify key parameters:\n",
    "\n",
    "    output_dir: Directory to save the model checkpoints.\n",
    "    evaluation_strategy: Frequency of evaluation during training.\n",
    "    per_device_train_batch_size: Batch size for training.\n",
    "    per_device_eval_batch_size: Batch size for evaluation.\n",
    "    num_train_epochs: Number of epochs to train the model.\n",
    "    save_steps: Number of steps between each checkpoint save.\n",
    "    eval_steps: Number of steps between each evaluation.\n",
    "    logging_dir: Directory to save training logs.\n",
    "    learning_rate: Learning rate for the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_training_args = TrainingArguments(\n",
    "    output_dir=\"model_checkpoints/auth\",\n",
    "    remove_unused_columns=False,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "auth_trainer = Trainer(\n",
    "    # model = model_clas_auth,\n",
    "    model_init= model_init_auth,\n",
    "    args = auth_training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = auth_dataset['train'],\n",
    "    eval_dataset = auth_dataset['test'],\n",
    "    tokenizer = processor_clas,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter Search\n",
    "\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-4, log=True,step=1e-5),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16]),\n",
    "        \"gradient_accumulation_steps\": trial.suggest_int(\"gradient_accumulation_steps\", 1, 4, step=1),\n",
    "        \"per_device_eval_batch_size\": trial.suggest_categorical(\"per_device_eval_batch_size\", [4, 8, 16]),\n",
    "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.1, 0.3, step=0.1),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 4, step=1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial_auth = auth_trainer.hyperparameter_search(n_trials=100, \n",
    "                                                 backend=\"optuna\",\n",
    "                                                 hp_space=optuna_hp_space, \n",
    "                                                 direction=\"maximize\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "sty_training_args = TrainingArguments(\n",
    "    output_dir=\"model_checkpoints/auth\",\n",
    "    remove_unused_columns=False,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sty_trainer = Trainer(\n",
    "    # model = vit_model_sty,\n",
    "    model_init= model_init_sty,\n",
    "    args = sty_training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = sty_dataset['train'],\n",
    "    eval_dataset = sty_dataset['test'],\n",
    "    tokenizer = processor_clas,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we evaluate the model on the test set and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials_sty = sty_trainer.hyperparameter_search(n_trials=100, \n",
    "                                                 backend=\"optuna\",\n",
    "                                                 hp_space=optuna_hp_space, \n",
    "                                                 direction=\"maximize\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Using Best Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the optimal hyperparameters through experimentation and evaluation, we proceed with training the model using these best parameters to achieve the highest possible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters_auth = best_trial_auth.hyperparameters\n",
    "auth_training_args = TrainingArguments(\n",
    "    output_dir=\"model_checkpoints/auth\",\n",
    "    remove_unused_columns=False,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=best_hyperparameters_auth[\"learning_rate\"],\n",
    "    per_device_train_batch_size=best_hyperparameters_auth[\"per_device_train_batch_size\"],\n",
    "    gradient_accumulation_steps=best_hyperparameters_auth[\"gradient_accumulation_steps\"],\n",
    "    per_device_eval_batch_size=best_hyperparameters_auth[\"per_device_eval_batch_size\"],\n",
    "    num_train_epochs=best_hyperparameters_auth[\"num_train_epochs\"],\n",
    "    warmup_ratio=best_hyperparameters_auth[\"warmup_ratio\"],\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "model_clas_auth = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint_clas,\n",
    "    num_labels = len(labels_author),\n",
    "    id2label = id2label_auth,\n",
    "    label2id = label2id_auth\n",
    ").to(device)\n",
    "\n",
    "auth_trainer = Trainer(\n",
    "    model = model_clas_auth,\n",
    "    # model_init= model_init_auth,\n",
    "    args = auth_training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = auth_dataset['train'],\n",
    "    eval_dataset = auth_dataset['test'],\n",
    "    tokenizer = processor_clas,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "auth_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_hyperparameters_sty = best_trials_sty.hyperparameters\n",
    "sty_training_args = TrainingArguments(\n",
    "    output_dir=\"model_checkpoints/sty\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=best_hyperparameters_sty[\"learning_rate\"],\n",
    "    per_device_train_batch_size=best_hyperparameters_sty[\"per_device_train_batch_size\"],\n",
    "    gradient_accumulation_steps=best_hyperparameters_sty[\"gradient_accumulation_steps\"],\n",
    "    per_device_eval_batch_size=best_hyperparameters_sty[\"per_device_eval_batch_size\"],\n",
    "    num_train_epochs=best_hyperparameters_sty[\"num_train_epochs\"],\n",
    "    warmup_ratio=best_hyperparameters_sty[\"warmup_ratio\"],\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "model_clas_sty = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint_clas,\n",
    "    num_labels = len(labels_sty),\n",
    "    id2label = id2label_sty,\n",
    "    label2id = label2id_sty\n",
    ").to(device)\n",
    "\n",
    "sty_trainer = Trainer(\n",
    "    model = model_clas_sty,\n",
    "    # model_init= model_init_sty,\n",
    "    args = sty_training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = sty_dataset['train'],\n",
    "    eval_dataset = sty_dataset['test'],\n",
    "    tokenizer = processor_clas,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "sty_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[100]\n",
    "image = sample['image']\n",
    "height,width = image.size\n",
    "display(image.resize((int(0.3*height),int(0.3*width))))\n",
    "author = sample['author']\n",
    "style = sample['style']\n",
    "print(f'Author: {id2label_auth[author]}')\n",
    "print(f'Style:  {id2label_sty[style]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint_clas)\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_auth = model_clas_auth(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint_clas)\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_sty = model_clas_sty(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_auth = logits_auth.argmax(-1).item()\n",
    "predicted_label_sty = logits_sty.argmax(-1).item()\n",
    "print(model_clas_auth.config.id2label[predicted_label_auth])\n",
    "print(model_clas_sty.config.id2label[predicted_label_sty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clas_auth.push_to_hub(\"Art_huggingface_auth\")\n",
    "model_clas_sty.push_to_hub(\"Art_huggingface_sty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
